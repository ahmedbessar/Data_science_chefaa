This project is a comprehensive data science and analytics initiative that involves several key components:

1. **Data Extraction using LLMs**
   The project starts with the LLMs_extract_datasets.py script, which demonstrates the use of Large Language Models (LLMs), specifically GPT-3.5-turbo, to extract datasets from a PDF document.
   This script takes a PDF file as input, reads its content, and uses the GPT-3.5-turbo model to identify and extract the relevant datasets. The extracted datasets are then saved as separate CSV files.
   The purpose of this script is to showcase the capabilities of LLMs in extracting structured data from unstructured text sources, such as PDF documents.

2. **dataset_1.csv and dataset_2.csv**
   These CSV files are the datasets extracted by the LLMs_extract_datasets.py script.
   The first dataset (dataset_1.csv) contains information about employees, including their ID, name, date of birth, salary, and department.
   The second dataset (dataset_2.csv) contains information about real estate properties, including their size, number of bedrooms, location, and price.
   These datasets are used in the subsequent Python scripts (part1_data_manipulation.ipynb, part2_statistical_analysis.ipynb) for data analysis and visualization.

3. **Data Cleaning and Aggregation (part1_data_manipulation.ipynb)**
   The part1_data_manipulation.ipynb Jupyter Notebook file focuses on data cleaning and aggregation tasks.
   It likely includes handling missing values, removing duplicates, and transforming the data into a format suitable for analysis.
   The notebook may also include code for fetching and integrating data from external APIs, such as financial data or geographic information, to enrich the analysis.
   The goal of this notebook is to prepare the datasets for further exploration and analysis.
   
4. **Statistical Analysis (part2_statistical_analysis.ipynb)**
   The part2_statistical_analysis.ipynb Jupyter Notebook file concentrates on statistical analysis of the prepared datasets.
   It may include tasks such as calculating descriptive statistics, performing hypothesis testing, and identifying trends and patterns in the data.
   The analysis in this notebook helps to gain insights and a deeper understanding of the data, which can inform decision-making or further investigations.
   
5. **Interactive Visualization (part3_tesla_stock_price.ipynb)**
   The part3_tesla_stock_price.ipynb Jupyter Notebook file focuses on interactive data visualization.
   It likely includes the creation of various charts, graphs, and dashboards to present the insights and findings from the data analysis.
   The interactive nature of the visualizations allows users to explore the data more intuitively and gain a better understanding of the underlying trends and relationships.
   The purpose of this notebook is to communicate the insights effectively and support decision-making processes.
   ![image](https://github.com/user-attachments/assets/cc878964-27b2-4754-ac27-218dcf5be44b)
   ![image](https://github.com/user-attachments/assets/be784955-2908-4dfd-b631-9624519ba94b)
![newplot](https://github.com/user-attachments/assets/38978ef8-b96e-4bfb-b2c4-eeae65b4e6a0)



Overall, this project showcases a comprehensive approach to data-driven problem-solving, combining the power of LLMs for data extraction, data cleaning and aggregation, statistical analysis, interactive visualization, and dashboard development. The project aims to demonstrate the candidate's skills and capabilities in data science, with the ultimate goal of deriving meaningful insights and supporting informed decision-making.
